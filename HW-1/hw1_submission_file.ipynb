{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9595a4ee-311f-46e1-b3cf-c8549a9dfc1f",
   "metadata": {},
   "source": [
    "## General Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e208bece-c1c1-4409-9422-22cabe16a608",
   "metadata": {},
   "source": [
    "# Submission Guidelines\n",
    "\n",
    "## 1. Complete the Jupyter Notebook\n",
    "- Fill in the missing code sections marked with `TODO`.  \n",
    "- Ensure all required implementations are completed correctly.  \n",
    "\n",
    "## 2. Include All Outputs\n",
    "- Run all cells in the notebook before submission.  \n",
    "- Ensure that outputs (e.g., printed results, tables, confusion matrices) are visible.  \n",
    "- Submissions with missing outputs will be penalized.  \n",
    "\n",
    "## 3. Submit the Notebook File (`.ipynb`) along with pdf of handwritten solutions\n",
    "- **Do NOT** submit the dataset file, sample.ipynb, or any saved plots.  \n",
    "\n",
    "## 4. Code Clarity & Documentation\n",
    "- Clearly define any extra variables you introduce.  \n",
    "- Use appropriate comments to explain modifications or additions to the code.  \n",
    "\n",
    "⚠️ **Failure to adhere to these guidelines may result in deductions.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7639dedf-64b7-4117-a9bf-d8eae7965ef4",
   "metadata": {},
   "source": [
    "## Gaussian Discriminant Classification\n",
    "\n",
    "This assignment focuses on obesity classification using Gaussian Discriminant Analysis (GDA). The goal is to predict whether an individual is obese based on health-related features, using three variants of GDA classifiers. The dataset contains attributes such as gender, family history of overweight, dietary habits, physical activity levels, and physiological measurements.\n",
    "\n",
    "### Rubric (Total = 70 points):\n",
    "1. **Data Preprocessing**:  \n",
    "   - Encode categorical variables (e.g., \"yes\"/\"no\" to 1/0).  **[3 points]**\n",
    "   - Remove redundant columns (`CAEC`, `CALC`, `MTRANS`).  **[3 points]**\n",
    "\n",
    "2. **Model Implementation**:  \n",
    "   Implement three GDA classifiers with different covariance assumptions:\n",
    "   - **Helper functions**: Functions to split class data and estimate parameters  **[20 points]**\n",
    "   - **C1**: Class-dependent covariance matrices.  **[12 points]**\n",
    "   - **C2**: Shared covariance matrix across classes.  **[12 points]**\n",
    "   - **C3**: Diagonal covariance matrix (feature independence).  **[12 points]**\n",
    "\n",
    "4. **Evaluation**:  \n",
    "   - Train/test split (`test_size=0.2`).  \n",
    "   - Compare performance using confusion matrices.  \n",
    "   - Analyze why one model outperforms others.  \n",
    "     1. **Q1**: Which model (C1, C2, or C3) performs best? **[4 points]**\n",
    "     2. **Q2**: Why does this model perform best?  **[4 points]**\n",
    "\n",
    "#### Dataset:\n",
    "- Features: `Gender`, `Age`, `Height`, `Weight`, `family_history_with_overweight`, etc.  \n",
    "- Target: `Obese` (1 = Not Obese, 2 = Obese).  \n",
    "\n",
    "\n",
    "All code that needs to be filled in is marked with the word \"*TODO*\". So make sure you do not forget anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d336304f-39e8-45e4-998d-7c727e898ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52a95469-122f-45fb-86e0-af6e76332d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>56.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>77.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>87.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>89.8</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Height  Weight family_history_with_overweight FAVC  FCVC  \\\n",
       "0  Female  21.0    1.62    64.0                            yes   no   2.0   \n",
       "1  Female  21.0    1.52    56.0                            yes   no   3.0   \n",
       "2    Male  23.0    1.80    77.0                            yes   no   2.0   \n",
       "3    Male  27.0    1.80    87.0                             no   no   3.0   \n",
       "4    Male  22.0    1.78    89.8                             no   no   2.0   \n",
       "\n",
       "   NCP       CAEC SMOKE  CH2O  SCC  FAF  TUE        CALC  \\\n",
       "0  3.0  Sometimes    no   2.0   no  0.0  1.0          no   \n",
       "1  3.0  Sometimes   yes   3.0  yes  3.0  0.0   Sometimes   \n",
       "2  3.0  Sometimes    no   2.0   no  2.0  1.0  Frequently   \n",
       "3  3.0  Sometimes    no   2.0   no  2.0  0.0  Frequently   \n",
       "4  1.0  Sometimes    no   2.0   no  0.0  0.0   Sometimes   \n",
       "\n",
       "                  MTRANS           NObeyesdad  \n",
       "0  Public_Transportation        Normal_Weight  \n",
       "1  Public_Transportation        Normal_Weight  \n",
       "2  Public_Transportation        Normal_Weight  \n",
       "3                Walking   Overweight_Level_I  \n",
       "4  Public_Transportation  Overweight_Level_II  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# TODO: Load in the `data.csv` file into a Pandas DataFrame.\n",
    "#\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45090aae-2cf6-49ea-82d4-d2f27a213524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Normal_Weight', 'Overweight_Level_I', 'Overweight_Level_II',\n",
       "       'Obesity_Type_I', 'Insufficient_Weight', 'Obesity_Type_II',\n",
       "       'Obesity_Type_III'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"NObeyesdad\"].unique()   #For my own visualization purpose to see the unique class in NObyesdad class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "094deef5-305d-441f-85e0-78c0bb081440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2]), array([ 559, 1552]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_obese = [\"Insufficient_Weight\", \"Normal_Weight\"]\n",
    "\n",
    "# Replace the cateogrical values with 1's and 2's for not obese and is obese respectfuly.\n",
    "df[\"Obese\"] = np.where(np.isin(df[\"NObeyesdad\"], not_obese), 1, 2)\n",
    "\n",
    "# Drop the Nobeyesdad column\n",
    "df.drop(\"NObeyesdad\", inplace = True, axis = 1) #axis= 1 specifies the column is being dropped   # the inplace= True ensures the change is applied directly to the DataFrame df without needing to reassign it.\n",
    "\n",
    "# View the class imbalance\n",
    "np.unique(df[\"Obese\"], return_counts = True) #return_counts=True also returns the count of each unique value, which helps identify if there is a class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "089e77e5-f48a-4a4a-a11d-8932ff9a7b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>Obese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>56.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>77.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>87.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>89.8</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Height  Weight family_history_with_overweight FAVC  FCVC  \\\n",
       "0  Female  21.0    1.62    64.0                            yes   no   2.0   \n",
       "1  Female  21.0    1.52    56.0                            yes   no   3.0   \n",
       "2    Male  23.0    1.80    77.0                            yes   no   2.0   \n",
       "3    Male  27.0    1.80    87.0                             no   no   3.0   \n",
       "4    Male  22.0    1.78    89.8                             no   no   2.0   \n",
       "\n",
       "   NCP SMOKE  CH2O  SCC  FAF  TUE  Obese  \n",
       "0  3.0    no   2.0   no  0.0  1.0      1  \n",
       "1  3.0   yes   3.0  yes  3.0  0.0      1  \n",
       "2  3.0    no   2.0   no  2.0  1.0      1  \n",
       "3  3.0    no   2.0   no  2.0  0.0      2  \n",
       "4  1.0    no   2.0   no  0.0  0.0      2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_cols = [\"CAEC\", \"CALC\", \"MTRANS\"]\n",
    "\n",
    "#\n",
    "# TODO: Remove (drop) the columns listed in `bas_cols` from the DataFrame.\n",
    "\n",
    "df = df.drop(columns=bad_cols)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "687b3e19-b46c-4818-8636-66805191c896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>Obese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>89.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Height  Weight  family_history_with_overweight  FAVC  FCVC  \\\n",
       "0     1.0  21.0    1.62    64.0                             1.0   0.0   2.0   \n",
       "1     1.0  21.0    1.52    56.0                             1.0   0.0   3.0   \n",
       "2     0.0  23.0    1.80    77.0                             1.0   0.0   2.0   \n",
       "3     0.0  27.0    1.80    87.0                             0.0   0.0   3.0   \n",
       "4     0.0  22.0    1.78    89.8                             0.0   0.0   2.0   \n",
       "\n",
       "   NCP  SMOKE  CH2O  SCC  FAF  TUE  Obese  \n",
       "0  3.0    0.0   2.0  0.0  0.0  1.0      1  \n",
       "1  3.0    1.0   3.0  1.0  3.0  0.0      1  \n",
       "2  3.0    0.0   2.0  0.0  2.0  1.0      1  \n",
       "3  3.0    0.0   2.0  0.0  2.0  0.0      2  \n",
       "4  1.0    0.0   2.0  0.0  0.0  0.0      2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {\n",
    "    \"Gender\": {\"Female\": 1.0, \"Male\": 0.0},\n",
    "    \"family_history_with_overweight\": {\"yes\": 1.0, \"no\": 0.0},\n",
    "    \"SMOKE\": {\"yes\": 1.0, \"no\": 0.0},\n",
    "    \"FAVC\": {\"yes\": 1.0, \"no\": 0.0},\n",
    "    \"SCC\": {\"yes\": 1.0, \"no\": 0.0},\n",
    "}\n",
    "\n",
    "#\n",
    "# TODO: Replace the values in the columns listed above in `mapping` with the new values.\n",
    "#here we can directly use the .replace in the defined mapping dictionary\n",
    "pd.set_option('future.no_silent_downcasting', True)  #because i got some kind of warning in notebook, so wanted to make the version of my pandas be compatible with future releases\n",
    "\n",
    "# Ex: Replace 'yes' with '1' and 'no' with '0' in all of the columns that have yes and no answers.\n",
    "df = df.replace(mapping)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88fbc0e2-40d4-46de-893e-bb7a9d0295a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dimensions: 13\n",
      "(2111, 13)\n",
      "(2111,)\n"
     ]
    }
   ],
   "source": [
    "x_cols = list(df.columns[:-1])  #This line creates a list, x_cols, containing the names of all the columns except the last one.\n",
    "y_cols = list(df.columns[-1:])  #This line creates a list, y_cols, containing the name of the last column. \n",
    "\n",
    "x = df[x_cols].to_numpy()   #converts the feature columns into a NumPy array\n",
    "y = df[y_cols].to_numpy().reshape(-1) #converts the target column into a 1D NumPy array y, where each element corresponds to a target value for a sample in x.\n",
    "\n",
    "#many ML algorithms expect the target variable to be a 1D array with shape (n,) instead of (n, 1)\n",
    "\n",
    "# Feature dimension (should be 13)\n",
    "d = x.shape[1]\n",
    "\n",
    "print(f\"Number of dimensions: {d}\")\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e60624c3-99a9-4c83-9abc-b386b5b3d31c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\racha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\racha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\racha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\racha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\racha\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a672bf95-14da-422a-a935-558c1a19cd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1688, 13)\n",
      "(1688,)\n",
      "(423, 13)\n",
      "(423,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split  #train_test_split is a utility function used to split datasets into training and testing subsets.\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(\n",
    "    x, y, test_size = 0.2, random_state = 42)   #test_size=0.2: This specifies the proportion of the dataset to include in the test split. Here, 0.2 means 20% of the data will be used for testing, and the remaining 80% will be used for training.\n",
    "\n",
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(Xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dffadd8-fc9a-40af-a503-44edb82292a8",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "You can implement the helper functions before or after implementing the Gaussian Discriminant below, though we recommend to implement the helper functions first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a12ca7fd-4e48-4b9c-8afc-7675806579d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions are smaller functions that perform a specific task and help make the code modular and reusable. These functions usually handle tasks that are needed by a main function but are complex enough to be separated out for clarity and better structure.\n",
    "#For example, in the case of implementing Gaussian Discriminant Analysis or other machine learning algorithms, we might need helper functions for tasks like:\n",
    "#Data Preprocessing: Normalizing or scaling data, handling missing values, etc.\n",
    "#Parameter Estimation: Computing means, variances, or covariances.\n",
    "#Matrix Operations: Implementing matrix multiplication, inversion, or other linear algebra tasks.\n",
    "\n",
    "\n",
    "\n",
    "def splitData(features, labels):\n",
    "    \"\"\"\n",
    "    Hint: Separate the features according to the corresponding labels, for example\n",
    "    if `features = [[1,1],[2,2],[3,3],[4,4]]` and `labels = [1,1,1,2]`, the \n",
    "    resulting feature1 and feature2 will be `features1 = [[1,1],[2,2],[3,3]]` \n",
    "    and `features2 = [[4,4]]`\n",
    "    \n",
    "    Input:\n",
    "        features: n*d matrix (n is the number of samples, d is the number of \n",
    "            dimensions of the feature)\n",
    "        labels: n vector\n",
    "        \n",
    "    Output:\n",
    "        features1: n1*d\n",
    "        features2: n2*d\n",
    "        \n",
    "    Notes: \n",
    "        n1+n2 = n, where n1 is the number of class 1 and n2 is the number of samples \n",
    "        from class 2.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Placeholders to store the separated features (feature1, feature2), \n",
    "    # can be ignored, removed or replaced with any following implementations\n",
    "    #features1 = np.zeros([np.sum(labels == 1), features.shape[1]])  \n",
    "    #features2 = np.zeros([np.sum(labels == 2), features.shape[1]])\n",
    "\n",
    "    #\n",
    "    # TODO: Fill in your code below! \n",
    "    features1 = features[labels == 1]  # Features corresponding to class 1\n",
    "    features2 = features[labels == 2]  # Features corresponding to class 2\n",
    "    \n",
    "    return features1, features2\n",
    "\n",
    "\n",
    "def computeMean(features):\n",
    "    \"\"\"\n",
    "    Compute the mean of input features\n",
    "    \n",
    "    Hint: Try to explore np.mean() for convenience\n",
    "    \n",
    "    Input \n",
    "        features: n*d array\n",
    "    \n",
    "    Output: \n",
    "        d-dimensional array\n",
    "        \n",
    "    \"\"\"\n",
    "    # Placeholders to store the mean for one class can be ignored, removed, \n",
    "    # or replaced with any following implementations\n",
    "    #m = np.zeros(features.shape[1])\n",
    "\n",
    "    #\n",
    "    # TODO: Fill in your code below! \n",
    "    m = np.mean(features, axis=0)\n",
    "    \n",
    "    return m\n",
    "\n",
    "\n",
    "def computeCov(features):\n",
    "    \"\"\"\n",
    "    Compute the covariance of input features\n",
    "    \n",
    "    Hint: Try to explore np.cov() for convenience\n",
    "    \n",
    "    Input: \n",
    "        features: n*d array\n",
    "        \n",
    "    Output: \n",
    "        d*d array\n",
    "        \n",
    "    \"\"\"\n",
    "    # Placeholders to store the covariance matrix for one class can be \n",
    "    # ignored, removed, or replaced with any following implementations\n",
    "    #S = np.eye(features.shape[1])\n",
    "\n",
    "    #\n",
    "    # TODO: Fill in your code below! \n",
    "    #\n",
    "    S = np.cov(features, rowvar=False)  ## rowvar=False ensures columns are treated as variables\n",
    "    return S\n",
    "\n",
    "\n",
    "def computePrior(labels):\n",
    "    \"\"\"\n",
    "    Compute the priors of input features\n",
    "    \n",
    "    Hint: p1 = numOf class1 / numOf all the data; same as p2\n",
    "    \n",
    "    Input: \n",
    "        features: Array of shape (n,)\n",
    "        \n",
    "    output: \n",
    "        Array of length size 2\n",
    "        \n",
    "    \"\"\"\n",
    "    # placeholders to store the priors for both class\n",
    "    # can be ignored, removed or replaced with any following implementations\n",
    "    #p = np.array([0.5, 0.5])\n",
    "\n",
    "    #\n",
    "    # TODO: Fill in your code below!  \n",
    "    # Compute priors\n",
    "    p1 = np.sum(labels == 1) / len(labels)  # Probability of class 1\n",
    "    p2 = np.sum(labels == 2) / len(labels)  # Probability of class 2\n",
    "    \n",
    "    p = np.array([p1, p2])\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c63eb4-3532-46f4-9c8b-5754acc477ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd037942-9b72-4e23-8122-acea82e5bb03",
   "metadata": {},
   "source": [
    "### Gaussian Discriminant C1\n",
    "\n",
    "For this assignment, you are going to implement 3 classifiers and corresponding helper functions.\n",
    "\n",
    "### Mathematical Formulation:\n",
    "\n",
    "The Gaussian Discriminant Analysis (GDA) model assumes that the class-conditional probability density functions are Gaussian:\n",
    "\n",
    "$$\n",
    "P(X \\mid Y = k) = \\frac{1}{(2\\pi)^{d/2} |\\Sigma_k|^{1/2}} \\exp\\left(-\\frac{1}{2} (X - \\mu_k)^T \\Sigma_k^{-1} (X - \\mu_k)\\right)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\mu_k$ is the mean vector for class $k$.\n",
    "- $\\Sigma_k$ is the covariance matrix for class $k$.\n",
    "- $|\\Sigma_k|$ is the determinant of $\\Sigma_k$.\n",
    "- $\\Sigma_k^{-1}$ is the inverse of the covariance matrix.\n",
    "\n",
    "The discriminant function for class $k$ is given by:\n",
    "\n",
    "$$\n",
    "g_k(X) = -\\frac{1}{2} (X - \\mu_k)^T \\Sigma_k^{-1} (X - \\mu_k) - \\frac{1}{2} \\log |\\Sigma_k| + \\log P(Y=k)\n",
    "$$\n",
    "\n",
    "where $P(Y=k)$ is the prior probability of class $k$.\n",
    "\n",
    "### Implementation Tips:\n",
    "- Compute $|\\Sigma|$ using `np.linalg.det()`.\n",
    "- Compute $\\Sigma^{-1}$ using `np.linalg.inv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "400bc901-634e-4e57-8938-b0d3716c5926",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiscriminant_C1:\n",
    "    \"\"\"\n",
    "    Classifier initialization\n",
    "    \n",
    "    Args\n",
    "      k: number of classes (2 for this assignment)\n",
    "      d: number of features; feature dimensions (13 for this assignment)\n",
    "      \n",
    "    \"\"\"\n",
    "    def __init__(self, k = 2, d = 13):\n",
    "        self.m = np.zeros((k, d))    # m1 and m2, store in 2*8 matrices\n",
    "        self.S = np.zeros((k, d, d)) # S1 and S2, store in 2*(8*8) matrices\n",
    "        self.p = np.zeros(2)         # p1 and p2, store in dimension 2 vectors\n",
    "\n",
    "    def fit(self, Xtrain, ytrain):\n",
    "        \"\"\"\n",
    "        Compute the parameters for both classes based on the training data\n",
    "        \n",
    "        \"\"\"\n",
    "        # Step 1: Split the data into two parts based on the labels\n",
    "        Xtrain1, Xtrain2 = splitData(Xtrain, ytrain)\n",
    "\n",
    "        # Step 2: Compute the parameters for each class\n",
    "        # m1, S1 for class 1\n",
    "        self.m[0,:] = computeMean(Xtrain1)\n",
    "        self.S[0,:,:] = computeCov(Xtrain1)\n",
    "        \n",
    "        # m2, S2 for class 2\n",
    "        self.m[1,:]  = computeMean(Xtrain2)\n",
    "        self.S[1,:,:] = computeCov(Xtrain2)\n",
    "        \n",
    "        # Priors for both class\n",
    "        self.p = computePrior(ytrain)\n",
    "\n",
    "    def predict(self, Xtest):\n",
    "        \"\"\"\n",
    "        Predict the labels for test data\n",
    "        \n",
    "        Input:\n",
    "            Xtest: n*d array\n",
    "            \n",
    "        Output:\n",
    "            predictions: n (all entries will be either number 1 or 2 to denote the labels)\n",
    "            \n",
    "        \"\"\"\n",
    "        # Placeholders to store the predictions can be ignored, removed or replaced with any \n",
    "        # following implementations\n",
    "        #predictions = np.zeros(Xtest.shape[0])\n",
    "\n",
    "        #\n",
    "        # TODO: Fill in your code below! \n",
    "        #\n",
    "        # Step1: plug in the test data features and compute the discriminant functions for both \n",
    "        # classes (you need to choose the correct discriminant functions) you will finall get two \n",
    "        # list of discriminant values (g1, g2), both have the shape n (n is the number of Xtest).\n",
    "\n",
    "\n",
    "        #\n",
    "        # TODO: Fill in your code below! \n",
    "        # Number of test samples\n",
    "        n = Xtest.shape[0]\n",
    "        \n",
    "        # Initialize arrays for storing discriminant function values\n",
    "        g1 = np.zeros(n)  # Discriminant function for class 1\n",
    "        g2 = np.zeros(n)# Discriminant function for class 2\n",
    "\n",
    "        detS1 = np.linalg.det(self.S[0])\n",
    "        invS1 = np.linalg.inv(self.S[0])\n",
    "        \n",
    "        detS2 = np.linalg.det(self.S[1])\n",
    "        invS2 = np.linalg.inv(self.S[1])\n",
    "\n",
    "        for i in range(Xtest.shape[0]):\n",
    "            \n",
    "            quad_term_1 = -0.5 * np.dot(Xtest[i] - self.m[0], np.dot(invS1, Xtest[i] - self.m[0]))         \n",
    "            determinant_term_1  = -0.5 * np.log(detS1 + 1e-12)                                             # determinant term for g1\n",
    "            prior_term_1= np.log(self.p[0] + 1e-12)                                                         # prior term for g1\n",
    "            g1[i] = quad_term_1 + determinant_term_1 + prior_term_1\n",
    "\n",
    "            # --- For Class 2 ---\n",
    "            quad_term_2 = -0.5 * np.dot(Xtest[i] - self.m[1], np.dot(invS2, Xtest[i] - self.m[1]))      # quadratic term for g2\n",
    "            determinant_term_2  = -0.5 * np.log(detS2 + 1e-12)                                          # determinant term for g2      \n",
    "            prior_term_2= np.log(self.p[1] + 1e-12)                                                     # prior term for g2\n",
    "            g2[i] = quad_term_2 + determinant_term_2 + prior_term_2\n",
    "\n",
    "        # Step2: If g1>g2, choose class1, otherwise choose class 2, you can convert g1 and g2 into \n",
    "        # your final predictions. \n",
    "        #predictions = np.where(g1 > g2, 1, 2)\n",
    "        # Ex: g1 = [0.1, 0.2, 0.4, 0.3], g2 = [0.3, 0.3, 0.3, 0.4], => predictions = [2, 2, 1, 2]\n",
    "        predictions = np.where(g1 > g2, 1, 2)\n",
    "\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf392441-246a-46a5-8162-6b752717cf34",
   "metadata": {},
   "source": [
    "### Now test your implementation by evalutating the performance of C1 on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "150559d2-15af-4192-b3b9-42488456bc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Gaussian Discriminant with class-dependent covariance\n",
      "[[108  25]\n",
      " [ 10 280]]\n"
     ]
    }
   ],
   "source": [
    "# Define the model with a Gaussian Discriminant function (class-dependent covariance)\n",
    "clf = GaussianDiscriminant_C1(2, d)\n",
    "clf.fit(Xtrain,ytrain)\n",
    "\n",
    "# Evaluate on test data\n",
    "predictions = clf.predict(Xtest)\n",
    "confusion_matrix = np.array([\n",
    "    [sum((ytest==1) & (predictions==1)), sum((ytest==2) & (predictions==1))],\n",
    "    [sum((ytest==1) & (predictions==2)), sum((ytest==2) & (predictions==2))]\n",
    "])\n",
    "\n",
    "print(\"Confusion Matrix for Gaussian Discriminant with class-dependent covariance\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cad80c38-d98b-4d0d-92c5-45cbe88d34f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of C1 classifier: 0.91725768321513\n"
     ]
    }
   ],
   "source": [
    "accuracy_C1_classifier = (108 + 280) / (108+25+10+280)\n",
    "\n",
    "print(\"Accuracy of C1 classifier:\", accuracy_C1_classifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad71dc73-a753-450d-9411-ae2974a8d495",
   "metadata": {},
   "source": [
    "### Gaussian Discriminant C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0b20da6-712a-480a-81b6-10aaa56dc9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiscriminant_C2:\n",
    "    \"\"\"\n",
    "    Classifier initialization\n",
    "    \n",
    "    Args\n",
    "      k: number of classes (2 for this assignment)\n",
    "      d: number of features; feature dimensions (13 for this assignment)\n",
    "      \n",
    "    \"\"\"\n",
    "    def __init__(self, k=2, d=8):\n",
    "        self.m = np.zeros((k, d))        # m1 and m2, store in 2*8 matrices\n",
    "        self.S = np.zeros((k, d, d))     # S1 and S2, store in 2*(8*8) matrices\n",
    "        self.shared_S = np.zeros((d, d)) # the shared convariance S that will be used for both classes\n",
    "        self.p = np.zeros(2)             # p1 and p2, store in dimension 2 vectors\n",
    "\n",
    "    def fit(self, Xtrain, ytrain):\n",
    "        \"\"\"\n",
    "        Compute the parameters for both classes based on the training data\n",
    "        \n",
    "        \"\"\"\n",
    "        # Step 1: Split the data into two parts based on the labels\n",
    "        Xtrain1, Xtrain2 = splitData(Xtrain, ytrain)\n",
    "\n",
    "        # Step 2: Compute the parameters for each class\n",
    "        # m1, S1 for class1\n",
    "        self.m[0,:] = computeMean(Xtrain1)\n",
    "        self.S[0,:,:] = computeCov(Xtrain1)\n",
    "        \n",
    "        # m2, S2 for class2\n",
    "        self.m[1,:] = computeMean(Xtrain2)\n",
    "        self.S[1,:,:] = computeCov(Xtrain2)\n",
    "        \n",
    "        # Priors for both class\n",
    "        self.p = computePrior(ytrain)\n",
    "\n",
    "        #\n",
    "        # TODO: Fill in your code below! \n",
    "        #\n",
    "        # Step 3: Compute the shared covariance matrix that is used for both class\n",
    "        # shared_S = p1 * S1 + p2 * S2\n",
    "        self.shared_S = (self.p[0] * self.S[0]) + (self.p[1] * self.S[1])\n",
    "\n",
    "    def predict(self, Xtest):\n",
    "        \"\"\"\n",
    "        Predict the labels for test data.\n",
    "        \n",
    "        Input:\n",
    "            Xtest: n*d\n",
    "            \n",
    "        Output:\n",
    "            predictions: n (all entries will be either number 1 or 2 to denote the labels)\n",
    "            \n",
    "        \"\"\"\n",
    "        # Placeholders to store the predictions can be ignored, removed or \n",
    "        # replaced with any following implementations\n",
    "        #predictions = np.zeros(Xtest.shape[0])\n",
    "\n",
    "        #\n",
    "        # TODO: Fill in your code below! \n",
    "        n = Xtest.shape[0]\n",
    "\n",
    "        # Initialize arrays for storing discriminant function values\n",
    "        g1 = np.zeros(n)  # Discriminant function for class 1\n",
    "        g2 = np.zeros(n)  # Discriminant function for class 2\n",
    "\n",
    "         # Step1: plug in the test data features and compute the discriminant functions for \n",
    "        # both classes (you need to choose the correct discriminant functions) you will final \n",
    "        # get two list of discriminant values (g1,g2), both have the shape n (n is the number \n",
    "        # of Xtest)\n",
    "\n",
    "        # TODO: Fill in your code below! \n",
    "        # Compute determinant and inverse of the shared covariance matrix\n",
    "        shared_S_det = np.linalg.det(self.shared_S+np.eye(self.shared_S.shape[0]))\n",
    "        shared_S_inv = np.linalg.inv(self.shared_S+np.eye(self.shared_S.shape[0]))\n",
    "\n",
    "        detS = np.linalg.det(self.shared_S)\n",
    "        invS = np.linalg.inv(self.shared_S)\n",
    "\n",
    "        for i in range(Xtest.shape[0]):\n",
    "            \n",
    "            \n",
    "            # Find the discriminnt for class 1 using the shared covariance matrix\n",
    "            quad_term_1 = -0.5 * np.dot(np.dot(Xtest[i] - self.m[0], shared_S_inv), Xtest[i] - self.m[0])\n",
    "            determinant_term_1 = -0.5 * np.log(shared_S_det)\n",
    "            prior_term_1 = np.log(self.p[0])\n",
    "            g1[i] = quad_term_1 + determinant_term_1 + prior_term_1\n",
    "\n",
    "            # Find the discriminnt for class 2 using the shared covariance matrix\n",
    "            quad_term_2 = -0.5 * np.dot(np.dot(Xtest[i] - self.m[1], shared_S_inv), Xtest[i] - self.m[1])\n",
    "            determinant_term_2 = -0.5 * np.log(shared_S_det)\n",
    "            prior_term_2 = np.log(self.p[1])\n",
    "            g2[i] = quad_term_2 + determinant_term_2 + prior_term_2\n",
    "        # TODO: Fill in your code below!\n",
    "        predictions = np.where(g1 > g2, 1, 2)\n",
    "       \n",
    "\n",
    "        # Step2: If g1>g2, choose class1, otherwise choose class 2, you can convert g1 and g2 \n",
    "        # into your final predictions. \n",
    "        #\n",
    "        # Ex: g1 = [0.1, 0.2, 0.4, 0.3], g2 = [0.3, 0.3, 0.3, 0.4], => predictions = [2, 2, 1, 2]\n",
    "\n",
    "        return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4385c783-3e6b-4162-91b0-0eadd22b20b1",
   "metadata": {},
   "source": [
    "### Now test your implementation by evalutating the performance of C2 on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96fc6c5f-a6e8-451f-82e9-062d563414ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Gaussian Discriminant with class-independent covariance\n",
      "[[103  17]\n",
      " [ 15 288]]\n"
     ]
    }
   ],
   "source": [
    "# Define the model with a Gaussian Discriminant function (class-independent covariance)\n",
    "clf = GaussianDiscriminant_C2(2, d)\n",
    "clf.fit(Xtrain,ytrain)\n",
    "\n",
    "# Evaluate on test data\n",
    "predictions = clf.predict(Xtest)\n",
    "confusion_matrix = np.array([\n",
    "    [sum((ytest==1) & (predictions==1)), sum((ytest==2) & (predictions==1))],\n",
    "    [sum((ytest==1) & (predictions==2)), sum((ytest==2) & (predictions==2))]\n",
    "])\n",
    "\n",
    "print(\"Confusion Matrix for Gaussian Discriminant with class-independent covariance\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "83e9c8be-fc27-4ce0-a744-79873389dcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of C2 classifier: 0.9243498817966903\n"
     ]
    }
   ],
   "source": [
    "accuracy_C2_classifier = (103 + 288) / (103+17+15+288)\n",
    "\n",
    "print(\"Accuracy of C2 classifier:\", accuracy_C2_classifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c2125e-ff31-4396-8e01-19337e98f3fd",
   "metadata": {},
   "source": [
    "### Gaussian Discriminant C3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f48d1ec2-da4e-4a1e-b2b7-b7f7352a5a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiscriminant_C3:\n",
    "    \"\"\"\n",
    "    Classifier initialization\n",
    "    \n",
    "    Args\n",
    "      k: number of classes (2 for this assignment)\n",
    "      d: number of features; feature dimensions (13 for this assignment)\n",
    "      \n",
    "    \"\"\"\n",
    "    def __init__(self, k = 2, d = 13):\n",
    "        self.m = np.zeros((k, d))        # m1 and m2, store in 2*8 matrices\n",
    "        self.S = np.zeros((k, d, d))     # S1 and S2, store in 2*(8*8) matrices\n",
    "        self.shared_S = np.zeros((d, d)) # the shared convariance S that will be used for both classes\n",
    "        self.p = np.zeros(2)             # p1 and p2, store in dimension 2 vectors\n",
    "\n",
    "    def fit(self, Xtrain, ytrain):\n",
    "        \"\"\"\n",
    "        Compute the parameters for both classes based on the training data\n",
    "        \n",
    "        \"\"\"\n",
    "        # Step 1: Split the data into two parts based on the labels\n",
    "        Xtrain1, Xtrain2 = splitData(Xtrain, ytrain)\n",
    "\n",
    "        # Step 2: Compute the parameters for each class\n",
    "        # m1, S1 for class1\n",
    "        self.m[0,:] = computeMean(Xtrain1)\n",
    "        self.S[0,:,:] = computeCov(Xtrain1)\n",
    "        \n",
    "        # m2, S2 for class2\n",
    "        self.m[1,:]  = computeMean(Xtrain2)\n",
    "        self.S[1,:,:] = computeCov(Xtrain2)\n",
    "        \n",
    "        # Priors for both class\n",
    "        self.p = computePrior(ytrain)\n",
    "\n",
    "        #\n",
    "        # TODO: Fill in your code below! \n",
    "        # Step 3: Make covariance matrices diagonal by extracting the diagonal elements\n",
    "        self.S[0, :, :] = np.diag(np.diag(self.S[0]))  # Keeping only the diagonal elements of S1\n",
    "        self.S[1, :, :] = np.diag(np.diag(self.S[1]))  # Keeping only the diagonal elements of S2\n",
    "\n",
    "        \n",
    "        # Step 3: Compute the diagonal of S1 and S2, since we assume each feature is independent, \n",
    "        # and has non diagonal entries cast to 0\n",
    "        #\n",
    "        # [[1,2],[2,4]] => [[1,0],[0,4]], try np.diag() twice\n",
    "\n",
    "        #\n",
    "        # TODO: Fill in your code below! \n",
    "        self.shared_S = (self.p[0] * self.S[0]) + (self.p[1] * self.S[1])\n",
    "        \n",
    "        # Step 4: Compute the shared covariance matrix that is used for both class \n",
    "        # shared_S = p1 * S1 + p2 * S2\n",
    "\n",
    "        \n",
    "    def predict(self, Xtest):\n",
    "        \"\"\"\n",
    "        Predict the labels for test data\n",
    "        \n",
    "        Input:\n",
    "            Xtest: n*d\n",
    "            \n",
    "        Output:\n",
    "            predictions: n (all entries will be either number 1 or 2 to denote the labels)\n",
    "            \n",
    "        \"\"\"\n",
    "        # Placeholders to store the predictions can be ignored, removed or replaced with any \n",
    "        # following implementations\n",
    "        #predictions = np.zeros(Xtest.shape[0])\n",
    "\n",
    "        #\n",
    "        # TODO: Fill in your code below! \n",
    "        n = Xtest.shape[0]\n",
    "    # Initialize arrays for storing discriminant function values\n",
    "        g1 = np.zeros(n)  # Discriminant function for class 1\n",
    "        g2 = np.zeros(n)  # Discriminant function for class 2\n",
    "        \n",
    "        # Step1: plug in the test data features and compute the discriminant functions for both \n",
    "        # classes (you need to choose the correct discriminant functions) you will finall get two \n",
    "        # list of discriminant values (g1, g2), both have the shape n (n is the number of Xtest).\n",
    "        #\n",
    "        # Please note here, currently we assume shared_S is a d*d diagonal matrix, the non-capital \n",
    "        # si^2 in the lecture formula will be the i-th entry on the diagonal.\n",
    "\n",
    "        #\n",
    "        # TODO: Fill in your code below! \n",
    "        # Extract diagonal elements of the shared covariance matrix (since it's diagonal)\n",
    "        diag_shared_S = np.diag(self.shared_S)\n",
    "\n",
    "        for i in range(n):\n",
    "            x = Xtest[i, :]\n",
    "            \n",
    "            # Compute the discriminant function g(x) for both classes\n",
    "            for c in range(2):  # Class 1 (c=0) and Class 2 (c=1)\n",
    "                mean_vec = self.m[c, :]  # Mean vector of class c\n",
    "                prior = self.p[c]  # Prior probability of class c\n",
    "\n",
    "                # Compute discriminant function for diagonal covariance matrix\n",
    "                variance_term = -0.5 * np.sum(((x - mean_vec) ** 2) / (diag_shared_S + 1e-12))\n",
    "                determinant_term = -0.5 * np.sum(np.log(diag_shared_S + 1e-12))  # Log of determinant\n",
    "                prior_term = np.log(prior + 1e-12)  # Log of prior probability\n",
    "                \n",
    "                g_x = variance_term + determinant_term + prior_term  # Final discriminant function value\n",
    "                \n",
    "                # Store the computed value\n",
    "                if c == 0:\n",
    "                    g1[i] = g_x  # Class 1 discriminant function\n",
    "                else:\n",
    "                    g2[i] = g_x  # Class 2 discriminant function\n",
    "\n",
    "        # Step2: If g1>g2, choose class1, otherwise choose class 2, you can convert g1 and g2 into \n",
    "        # your final predictions\n",
    "        #\n",
    "        # Ex: g1 = [0.1, 0.2, 0.4, 0.3], g2 = [0.3, 0.3, 0.3, 0.4], => predictions = [2,2,1,2]\n",
    "        predictions = np.where(g1 > g2, 1, 2)\n",
    "\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37671861-9363-435e-9ff0-485759010128",
   "metadata": {},
   "source": [
    "### Now test your implementation by evalutating the performance of C3 on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "610166fc-65af-4e6e-9218-22312eb5318d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Gaussian Discriminant with diagonal covariance\n",
      "[[ 96  28]\n",
      " [ 22 277]]\n"
     ]
    }
   ],
   "source": [
    "# Define the model with a Gaussian Discriminant function (diagonal covariance)\n",
    "clf = GaussianDiscriminant_C3(2, d)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "# Evaluate on test data\n",
    "predictions = clf.predict(Xtest)\n",
    "confusion_matrix = np.array([\n",
    "    [sum((ytest==1) & (predictions==1)),sum((ytest==2) & (predictions==1))],\n",
    "    [sum((ytest==1) & (predictions==2)),sum((ytest==2) & (predictions==2))]\n",
    "])\n",
    "\n",
    "print(\"Confusion Matrix for Gaussian Discriminant with diagonal covariance\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f922b79-e5d1-48bd-8b5c-d0a90de4fc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of C3 classifier: 0.8817966903073287\n"
     ]
    }
   ],
   "source": [
    "accuracy_C3_classifier = (96 + 277) / (96 + 28 + 22 + 277)\n",
    "print(\"Accuracy of C3 classifier:\", accuracy_C3_classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529c7144-b763-4ce6-9bb5-696c972e7992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4dd49993-7d37-483b-8a99-e5f81d4ed53c",
   "metadata": {},
   "source": [
    "### Q1: Which model performs the best? \n",
    "\n",
    "#The model C2 performs the best. \n",
    "\n",
    "\n",
    "### Q2: Why does this model perform the best?\n",
    "#The model C2 has the lowest false positives among all the models. In case of false negative it has slighly higher false negatives than C1 but lower than C3. Moreover, C2 model has the highest accuracy(92.43%) as compared to C1(91.7%) and C3 (88.17%). C1 has the overfitting risk.Similarly, C3 oversimplifies the model by assuming that each feature is irrelevant to others. While the model C2 balances the bias and variances leading better generalizations. Instead of directly utilizing independent covariance matrices, C2 computes a covariance matrix of all the data. This smooths out variations, preventing overfitting. So I think C2 this model performs the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c138208-dbde-4a57-9b8e-6a5f20f960e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
